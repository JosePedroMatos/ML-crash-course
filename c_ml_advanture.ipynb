{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c5ee395",
   "metadata": {},
   "source": [
    "# Using \"machine learning\" to approximate a 3rd degree polynomial in 5D Space\n",
    "\n",
    "In this notebook, we will:\n",
    "- Generate a synthetic 3rd degree polynomial signal in a 5D input space.\n",
    "- Plot the true signal along with noisy observations (including a few outliers).\n",
    "- Build a pipeline that normalizes data, applies PCA (dimentionality reduction), and performs polynomial regression with regularization.\n",
    "- Illustrate overfitting by using an excessively high polynomial degree.\n",
    "- Use k-fold cross-validation with grid search to select the best polynomial degree and regularization penalty.\n",
    "- Fit the final model and evaluate it on a test set.\n",
    "\n",
    "<i>(To make it simple, we are also using a polynomial to approximate the function - sorry, it's not **really** machine learning...)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc973c20",
   "metadata": {},
   "source": [
    "## Generate the synthetic data\n",
    "\n",
    "We create a dataset with a few samples ($X$):\n",
    "- The first feature, ($x_1$), is in the range ($[-1, 1]$).\n",
    "- The true signal ($y$) is given by:\n",
    "  \n",
    "$$\n",
    "  y = 2x_1^3 - 3x_1^2 + x_1 + 5 + 0.1x_2 + 0.04x_3^2 \n",
    "$$\n",
    "  \n",
    "- We add Gaussian noise and a few large outliers.\n",
    "- The final input ($X$) is 5-dimensional: the first column is ($x_1$), and the other 4 columns are not as important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f955bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "n_samples = 200\n",
    "\n",
    "# Generate X values and create the true signal\n",
    "t = np.linspace(-1, 1, n_samples)\n",
    "X = np.column_stack((t, np.random.randn(n_samples, 4)))\n",
    "\n",
    "def true_signal(X):\n",
    "    return 2 * X[:, 0]**3 - 3 * X[:, 0]**2 + X[:, 0] + 5 + 0.1*X[:, 1] + 0.05* X[:, 2]**2\n",
    "y_true = true_signal(X) \n",
    "\n",
    "# Generate noise and create y (observations)\n",
    "noise_scale = 0.5\n",
    "noise = np.random.normal(scale=noise_scale, size=n_samples)\n",
    "y_noisy = y_true + noise\n",
    "\n",
    "# Inject a few outliers\n",
    "n_outliers = 2\n",
    "outlier_indices = np.random.choice(n_samples, n_outliers, replace=False)\n",
    "y_noisy[outlier_indices] += np.random.choice([5, -5], size=n_outliers)\n",
    "\n",
    "# Plot the true signal and the noisy data points (against t)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(t, y_true, label='True signal', color='black', linewidth=2)\n",
    "plt.scatter(t, y_noisy, label='Noisy observations', color='red', alpha=0.6)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('y')\n",
    "plt.title('True signal and noisy observations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2e3858",
   "metadata": {},
   "source": [
    "## Build a pipeline & illustrate overfitting\n",
    "\n",
    "We create a pipeline that:\n",
    "- **Normalizes** the data.\n",
    "- Applies **PCA** to reduce the dimensionality from 5D to 3D.\n",
    "- Generates polynomial features.\n",
    "- Uses **L2 regularization** for regression.\n",
    "\n",
    "To illustrate overfitting, we intentionally set the polynomial degree too high (e.g. degree=15) and observe how the model fits the training data.\n",
    "\n",
    "You may test the following to improve the situation:\n",
    "- Less PCA components.\n",
    "- lower polynomial degree.\n",
    "- higher alpha (stronger regularization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with an excessively high polynomial degree (15) to illustrate overfitting\n",
    "overfit_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('poly', PolynomialFeatures(degree=10, include_bias=True)),\n",
    "    ('regularization', Ridge(alpha=0.001))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "overfit_pipeline.fit(X, y_noisy)\n",
    "\n",
    "# Generate predictions on the training t values (we need to build the corresponding 5D X)\n",
    "# For visualization, we'll only vary t and use random noise for the other features (set them to zero)\n",
    "X_vis = np.column_stack((t, np.zeros((n_samples, 4))))\n",
    "y_pred_overfit = overfit_pipeline.predict(X_vis)\n",
    "\n",
    "# Plot the overfitted model prediction\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(t, y_true, label='True signal', color='black', linewidth=2)\n",
    "plt.scatter(t, y_noisy, label='Noisy observations', color='red', alpha=0.6)\n",
    "plt.plot(t, y_pred_overfit, label='Prediction (overfit)', linewidth=4)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('y')\n",
    "plt.title('Overfitting illustration with high-degree polynomial')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac1ec7",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with grid search\n",
    "\n",
    "Now we perform a grid search with k-fold cross-validation to tune:\n",
    "- The number of PCA components (dimensionality).\n",
    "- The polynomial degree.\n",
    "- The regularization penalty (alpha).\n",
    "\n",
    "We use only a few combinations to keep the grid search fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d065a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline (using placeholders for hyperparameters to be tuned)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('poly', PolynomialFeatures(include_bias=True)),\n",
    "    ('regularization', Ridge())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'pca__n_components': [2, 3, 4, 5], # Try different dimensionalities\n",
    "    'poly__degree': [3, 4, 5],        # Try degrees around the true 3rd degree signal\n",
    "    'regularization__alpha': [0.01, 1.0, 10.0, 100.0]   # Different regularization strengths\n",
    "}\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Create and run the GridSearchCV (MAE scoring is used)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X, y_noisy)\n",
    "\n",
    "\n",
    "# Get the retrained best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a1742",
   "metadata": {},
   "source": [
    "## Evaluate on extrapolated test data\n",
    "\n",
    "We now take the best model from the grid search and:\n",
    "- Fit it on the full training data.\n",
    "- Generate a test dataset with $X$ values that slightly extrapolate the training range (e.g., $[-1.2, 1.2]$).\n",
    "- Plot the true signal, the trainind data, and the model predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bbd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate an extrapolated grid for t\n",
    "t_extrap = np.linspace(-1.2, 1.2, n_samples)\n",
    "X_extrap = np.column_stack((t_extrap, 0*np.random.randn(n_samples, 4)))\n",
    "\n",
    "\n",
    "# Compute the true signal on the extrapolated grid\n",
    "y_true_extrap = true_signal(X_extrap) \n",
    "\n",
    "# Generate multiple predictions due to noise in the extra dimensions.\n",
    "# We'll generate, for example, 10 prediction curves.\n",
    "n_predictions = 10\n",
    "predictions = []\n",
    "\n",
    "y_pred = best_model.predict(X_extrap)\n",
    "\n",
    "# Plot the true signal, training data, and multiple predicted signals.\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot the true signal line (extrapolated)\n",
    "plt.plot(t_extrap, y_true_extrap, label=\"True signal\", color=\"black\", linewidth=2)\n",
    "# Plot the original training data (from previous generation)\n",
    "plt.scatter(t, y_noisy, label=\"Training data\", color=\"red\", alpha=0.6)\n",
    "# Plot the predicted curve\n",
    "plt.plot(t_extrap, y_pred, label=\"Prediction\", linewidth=4)\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('y')\n",
    "plt.title('Training data, true Signal, and multiple extrapolated predictions')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09cfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2d88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
